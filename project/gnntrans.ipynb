{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from torch.nn import Sequential, Linear, ReLU, Softmax\n",
    "from scipy.sparse import random\n",
    "from scipy import stats\n",
    "from numpy.random import default_rng\n",
    "# circuit-sim\n",
    "# import subcircuit as sc\n",
    "# import PySpice.Logging.Logging as Logging\n",
    "# logger = Logging.setup_logging()\n",
    "# from PySpice.Spice.Netlist import Circuit, SubCircuit, SubCircuitFactory\n",
    "# from PySpice.Unit import *\n",
    "# from PySpice.Spice.NgSpice.Shared import NgSpiceShared\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Type | Value                          | Type | Value                              |\n",
    "|------|--------------------------------|------|------------------------------------|\n",
    "| Node | capacitance value              | Path | input transition time              |\n",
    "|      | num of input nodes             |      | drive strength of drive cell       |\n",
    "|      | total input cap                |      | functionality  of drive cell       |\n",
    "|      | total output cap               |      | drive strength of load cell        |\n",
    "|      | number of connected resistance |      | functionality of load cell         |\n",
    "|      | total input resistance         |      | effective capacitance of load cell |\n",
    "|      | total output resistance        |      | wire path Elmore delay             |\n",
    "|      | Elmore downstream capacitance  |      | wire path D2M delay                |\n",
    "|      | Elmore stage delay             |      |                                    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adj Matrix:  [[0 1 0 0]\n",
      " [1 0 1 0]\n",
      " [0 1 0 1]\n",
      " [0 0 1 0]]\n",
      "Paths:  [[0, 1, 2, 3]]\n",
      "Path Features:  tensor([[2., 2., 1., 5., 1., 5., 4., 1.]])\n",
      "Adj Matrix with Edge Weights:  [[0 1 0 0]\n",
      " [1 0 2 0]\n",
      " [0 2 0 5]\n",
      " [0 0 5 0]]\n",
      "Resistance:  [(0, 1, 1), (1, 2, 2), (2, 3, 5)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuwcse/anaconda3/envs/graph/lib/python3.10/site-packages/scipy/sparse/_base.py:752: VisibleDeprecationWarning: Please use `.todense()` instead\n",
      "  warn(np.VisibleDeprecationWarning(\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import random\n",
    "\n",
    "''' Sample Graph '''\n",
    "# graph configuration\n",
    "num_nodes = 4\n",
    "num_edges = 3\n",
    "num_path_features = 8\n",
    "num_node_features = 9\n",
    "\n",
    "# set seed for random number generator\n",
    "random.seed(42)\n",
    "\n",
    "# create a linear graph with 4 nodes and 3 edges\n",
    "G = nx.path_graph(4)\n",
    "\n",
    "# assign random values to node attributes\n",
    "for i in range(num_nodes):\n",
    "    G.nodes[i]['capacitance'] = random.randint(1, 5)\n",
    "    if i == 0:\n",
    "        G.nodes[i]['num_input_nodes'] = 0\n",
    "    else:\n",
    "        G.nodes[i]['num_input_nodes'] = 1\n",
    "\n",
    "    G.nodes[i]['input_cap'] = 1\n",
    "    G.nodes[i]['output_cap'] = 1\n",
    "\n",
    "    if i == num_nodes - 1:\n",
    "        G.nodes[i]['connected_resistance'] = 0\n",
    "    else:\n",
    "        G.nodes[i]['connected_resistance'] = 1\n",
    "\n",
    "    G.nodes[i]['input_resistance'] = 1\n",
    "    G.nodes[i]['output_resistance'] = 1\n",
    "    G.nodes[i]['elmore_cap'] = 1\n",
    "\n",
    "    if i == 0:\n",
    "        G.nodes[i]['elmore_delay'] = 0\n",
    "    else:\n",
    "        G.nodes[i]['elmore_delay'] = 1\n",
    "\n",
    "\n",
    "# get the adjacency matrix\n",
    "M_adj = nx.adjacency_matrix(G)\n",
    "print(\"Adj Matrix: \", M_adj.A)\n",
    "\n",
    "# extract all paths\n",
    "paths = nx.all_simple_paths(G, source=0, target=3)\n",
    "list_of_paths = list(paths)\n",
    "print(\"Paths: \", list_of_paths)\n",
    "\n",
    "# create a matrix of [num_paths, num_path_features]\n",
    "M_path = torch.zeros(len(list_of_paths), num_path_features)\n",
    "\n",
    "# assign random value to the paths\n",
    "for i in range(len(list_of_paths)):\n",
    "    for j in range(num_path_features):\n",
    "        M_path[i,j] = random.randint(1, 5)\n",
    "\n",
    "print(\"Path Features: \", M_path)\n",
    "\n",
    "# assign random value to the edges\n",
    "for i in range(num_nodes):\n",
    "    for j in range(num_nodes):\n",
    "        if M_adj.A[i,j] == 1:\n",
    "            G.edges[i,j]['weight'] = random.randint(1, 5)\n",
    "\n",
    "# add edge weights to adjacency matrix\n",
    "for i in range(num_nodes):\n",
    "    for j in range(num_nodes):\n",
    "        if M_adj.A[i,j] == 1:\n",
    "            M_adj.A[i,j] = G.edges[i,j]['weight']\n",
    "\n",
    "print(\"Adj Matrix with Edge Weights: \", nx.adjacency_matrix(G).A)\n",
    "\n",
    "print(\"Resistance: \", G.edges.data('weight'))\n",
    "\n",
    "# plot the graph with edge weights\n",
    "# nx.draw(G, with_labels=True, font_weight='bold')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$x_i^{l_1} = ReLU(W_1^{l_1}x_i^{l_1-1}+W_2^{l_1}a_{iu}\\sum_{u\\in \\mathcal{N}(v_i)}x_u^{l_1-1})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:  tensor([[0.1052, 0.0341, 0.0045, 0.0000, 0.0177, 0.0043, 0.0000, 0.0000, 0.0225],\n",
      "        [0.2240, 0.1275, 0.0209, 0.0452, 0.0696, 0.0087, 0.0000, 0.0000, 0.1000],\n",
      "        [0.3948, 0.2214, 0.1019, 0.1659, 0.1741, 0.0523, 0.0000, 0.0000, 0.1030],\n",
      "        [0.3837, 0.2295, 0.0763, 0.1510, 0.1672, 0.0361, 0.0000, 0.0000, 0.1748]],\n",
      "       grad_fn=<ReluBackward0>)\n",
      "Output Shape:  torch.Size([4, 9])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.utils import to_dense_adj\n",
    "# torch random seed\n",
    "torch.manual_seed(42)\n",
    "\n",
    "class L1_GNNModule(nn.Module):\n",
    "    \"\"\"\n",
    "    Modified GraphSAGE module with weighted aggregation\n",
    "    \"\"\"\n",
    "    def __init__(self, num_input_features, num_output_features):\n",
    "        super().__init__()\n",
    "        self.W1 = nn.Parameter(torch.randn(num_input_features, num_output_features) * 0.01)\n",
    "        self.W2 = nn.Parameter(torch.randn(num_input_features, num_output_features) * 0.01)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        neighbors_agg = to_dense_adj(edge_index, edge_attr=edge_weight, max_num_nodes=num_nodes).squeeze(0)\n",
    "        neighbors_agg = torch.matmul(neighbors_agg, x)\n",
    "        # linear transformation\n",
    "        out = torch.matmul(neighbors_agg, self.W2) + torch.matmul(x, self.W1)\n",
    "        # relu activation\n",
    "        out = torch.relu(out)\n",
    "        return out\n",
    "\n",
    "'''Test the GNN Module'''\n",
    "# input features from node attributes\n",
    "x = torch.tensor([[G.nodes[i]['capacitance'],\n",
    "                    G.nodes[i]['num_input_nodes'],\n",
    "                    G.nodes[i]['input_cap'],\n",
    "                    G.nodes[i]['output_cap'],\n",
    "                    G.nodes[i]['connected_resistance'],\n",
    "                    G.nodes[i]['input_resistance'],\n",
    "                    G.nodes[i]['output_resistance'],\n",
    "                    G.nodes[i]['elmore_cap'],\n",
    "                    G.nodes[i]['elmore_delay']] for i in range(num_nodes)], dtype=torch.float)\n",
    "\n",
    "\n",
    "# extract edge index from adjacency matrix from networkx\n",
    "edge_index = torch.tensor([[i, j] for i in range(num_nodes) for j in range(num_nodes) if M_adj.A[i,j] != 0], dtype=torch.long).t()\n",
    "\n",
    "# extract edge weights from networkx\n",
    "edge_weight = torch.tensor([G.edges[i,j]['weight'] for i in range(num_nodes) for j in range(num_nodes) if M_adj.A[i,j] != 0], dtype=torch.float)\n",
    "\n",
    "gnn = L1_GNNModule(num_node_features, num_node_features)\n",
    "out = gnn(x, edge_index, edge_weight)\n",
    "\n",
    "print(\"Output: \", out)\n",
    "print(\"Output Shape: \", out.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\tilde{a}_{iu}^{(k, l_2)} = softmax(\\frac{W_Q^{(k, l_2)}x_i^{(L_1+l_2-1)}(W_k^{(k,l_2)}x_u^{(L_1+l_2-1)})}{\\sqrt{d_k}})$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$x_i^{(L_1+l_2)} = x_i^{(L_1+l_2-1)} +  W_3^{(l_2)}||^{\\mathcal{K}}_{k=1}\\sum_{u\\in \\mathcal{V}}\\tilde{a}_{iu}^{(k, l_2)}(W_V^{(k, l_2)}x_u^{(L_1+l_2-1)})$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:  tensor([[0.0002, 0.0001, 0.0000, 0.0000, 0.0003, 0.0011, 0.0006, 0.0000, 0.0005],\n",
      "        [0.0002, 0.0001, 0.0000, 0.0000, 0.0003, 0.0011, 0.0006, 0.0000, 0.0005],\n",
      "        [0.0002, 0.0001, 0.0000, 0.0000, 0.0003, 0.0011, 0.0006, 0.0000, 0.0005],\n",
      "        [0.0002, 0.0001, 0.0000, 0.0000, 0.0003, 0.0011, 0.0006, 0.0000, 0.0005]],\n",
      "       grad_fn=<ReluBackward0>)\n",
      "Output Shape:  torch.Size([4, 9])\n"
     ]
    }
   ],
   "source": [
    "class L2_GNNModule(nn.Module):\n",
    "    \"\"\"Multi-head Attention GNN module\n",
    "    \"\"\"\n",
    "    def __init__(self, num_input_features, num_output_features):\n",
    "        super().__init__()\n",
    "        self.Wq = nn.Parameter(torch.randn(num_input_features, num_output_features) * 0.01)\n",
    "        self.Wk = nn.Parameter(torch.randn(num_input_features, num_output_features) * 0.01)\n",
    "        self.Wv = nn.Parameter(torch.randn(num_input_features, num_output_features) * 0.01)\n",
    "        self.W3 = nn.Parameter(torch.randn(num_input_features, num_output_features) * 0.01)\n",
    "\n",
    "    def forward(self, x, edge_index=None, edge_weight=None):\n",
    "        # self-attention map A\n",
    "        A = torch.matmul(torch.matmul(x, self.Wq), torch.matmul(x, self.Wk).t())\n",
    "        A = A / torch.sqrt(torch.tensor(num_node_features, dtype=torch.float))\n",
    "        A = torch.softmax(A, dim=1)\n",
    "\n",
    "        # Based on the single self-attention map, the node representation of vi can be updated based on aggregating information using a multi-head self-attention map:\n",
    "        \n",
    "        # Collaborative Multi-Head Attention\n",
    "        # concatenate the outputs of all heads\n",
    "        \n",
    "\n",
    "'''Test the GNN Module'''\n",
    "# input features from node attributes\n",
    "x = torch.tensor([[G.nodes[i]['capacitance'],\n",
    "                    G.nodes[i]['num_input_nodes'],\n",
    "                    G.nodes[i]['input_cap'],\n",
    "                    G.nodes[i]['output_cap'],\n",
    "                    G.nodes[i]['connected_resistance'],\n",
    "                    G.nodes[i]['input_resistance'],\n",
    "                    G.nodes[i]['output_resistance'],\n",
    "                    G.nodes[i]['elmore_cap'],\n",
    "                    G.nodes[i]['elmore_delay']] for i in range(num_nodes)], dtype=torch.float)\n",
    "\n",
    "gnn = L2_GNNModule(num_node_features, num_node_features)\n",
    "out = gnn(x)\n",
    "\n",
    "print(\"Output: \", out)\n",
    "print(\"Output Shape: \", out.shape)\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
