{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from torch.nn import Sequential, Linear, ReLU, Softmax\n",
    "from torch.nn import functional as F\n",
    "from scipy.sparse import random\n",
    "from scipy import stats\n",
    "from numpy.random import default_rng\n",
    "\n",
    "from gmm import GMM\n",
    "# circuit-sim\n",
    "# import subcircuit as sc\n",
    "# import PySpice.Logging.Logging as Logging\n",
    "# logger = Logging.setup_logging()\n",
    "# from PySpice.Spice.Netlist import Circuit, SubCircuit, SubCircuitFactory\n",
    "# from PySpice.Unit import *\n",
    "# from PySpice.Spice.NgSpice.Shared import NgSpiceShared\n",
    "# mps_device = torch.device(\"mps\")\n",
    "mps_device = torch.device(\"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Type | Value                          | Type | Value                              |\n",
    "|------|--------------------------------|------|------------------------------------|\n",
    "| Node | capacitance value              | Path | input transition time              |\n",
    "|      | num of input nodes             |      | drive strength of drive cell       |\n",
    "|      | total input cap                |      | functionality  of drive cell       |\n",
    "|      | total output cap               |      | drive strength of load cell        |\n",
    "|      | number of connected resistance |      | functionality of load cell         |\n",
    "|      | total input resistance         |      | effective capacitance of load cell |\n",
    "|      | total output resistance        |      | wire path Elmore delay             |\n",
    "|      | ~~Elmore downstream capacitance~~  |      | wire path D2M delay                |\n",
    "|      | ~~Elmore stage delay~~             |      |                                    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import networkx as nx\n",
    "# import random\n",
    "\n",
    "# ''' Sample Graph '''\n",
    "# # graph configuration\n",
    "# num_nodes = 4\n",
    "# num_edges = 3\n",
    "# num_path_features = 8\n",
    "# num_node_features = 9\n",
    "\n",
    "# # set seed for random number generator\n",
    "# random.seed(42)\n",
    "\n",
    "# # create a linear graph with 4 nodes and 3 edges\n",
    "# G = nx.path_graph(4)\n",
    "\n",
    "# # assign random values to node attributes\n",
    "# for i in range(num_nodes):\n",
    "#     G.nodes[i]['capacitance'] = random.randint(1, 5)\n",
    "#     if i == 0:\n",
    "#         G.nodes[i]['num_input_nodes'] = 0\n",
    "#     else:\n",
    "#         G.nodes[i]['num_input_nodes'] = 1\n",
    "\n",
    "#     G.nodes[i]['input_cap'] = 1\n",
    "#     G.nodes[i]['output_cap'] = 1\n",
    "\n",
    "#     if i == num_nodes - 1:\n",
    "#         G.nodes[i]['connected_resistance'] = 0\n",
    "#     else:\n",
    "#         G.nodes[i]['connected_resistance'] = 1\n",
    "\n",
    "#     G.nodes[i]['input_resistance'] = 1\n",
    "#     G.nodes[i]['output_resistance'] = 1\n",
    "#     G.nodes[i]['elmore_cap'] = 1\n",
    "\n",
    "#     if i == 0:\n",
    "#         G.nodes[i]['elmore_delay'] = 0\n",
    "#     else:\n",
    "#         G.nodes[i]['elmore_delay'] = 1\n",
    "\n",
    "\n",
    "# # get the adjacency matrix\n",
    "# M_adj = nx.adjacency_matrix(G)\n",
    "# print(\"Adj Matrix: \", M_adj.A)\n",
    "\n",
    "# # extract all paths\n",
    "# paths = nx.all_simple_paths(G, source=0, target=3)\n",
    "# list_of_paths = list(paths)\n",
    "# print(\"Paths: \", list_of_paths)\n",
    "\n",
    "# # create a matrix of [num_paths, num_path_features]\n",
    "# M_path = torch.zeros(len(list_of_paths), num_path_features)\n",
    "\n",
    "# # assign random value to the paths\n",
    "# for i in range(len(list_of_paths)):\n",
    "#     for j in range(num_path_features):\n",
    "#         M_path[i,j] = random.randint(1, 5)\n",
    "\n",
    "# print(\"Path Features: \", M_path)\n",
    "\n",
    "# # assign random value to the edges\n",
    "# for i in range(num_nodes):\n",
    "#     for j in range(num_nodes):\n",
    "#         if M_adj.A[i,j] == 1:\n",
    "#             G.edges[i,j]['weight'] = random.randint(1, 5)\n",
    "\n",
    "# # add edge weights to adjacency matrix\n",
    "# for i in range(num_nodes):\n",
    "#     for j in range(num_nodes):\n",
    "#         if M_adj.A[i,j] == 1:\n",
    "#             M_adj.A[i,j] = G.edges[i,j]['weight']\n",
    "\n",
    "# print(\"Adj Matrix with Edge Weights: \", nx.adjacency_matrix(G).A)\n",
    "\n",
    "# print(\"Resistance: \", G.edges.data('weight'))\n",
    "\n",
    "# # plot the graph with edge weights\n",
    "# nx.draw(G, with_labels=True, font_weight='bold')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$x_i^{l_1} = ReLU(W_1^{l_1}x_i^{l_1-1}+W_2^{l_1}a_{iu}\\sum_{u\\in \\mathcal{N}(v_i)}x_u^{l_1-1})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Test the GNN Module'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.utils import to_dense_adj\n",
    "# torch random seed\n",
    "torch.manual_seed(42)\n",
    "\n",
    "class L1_GNNModule(nn.Module):\n",
    "    \"\"\"\n",
    "    Modified GraphSAGE module with weighted aggregation\n",
    "    \"\"\"\n",
    "    def __init__(self, num_input_features, num_output_features):\n",
    "        super().__init__()\n",
    "        self.W1 = nn.Parameter(torch.randn(num_input_features, num_output_features) * 0.01).to(mps_device)\n",
    "        self.W2 = nn.Parameter(torch.randn(num_input_features, num_output_features) * 0.01).to(mps_device)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        neighbors_agg = to_dense_adj(edge_index, edge_attr=edge_weight).squeeze(0).to(mps_device)\n",
    "        neighbors_agg = torch.matmul(neighbors_agg.float(), x.float())\n",
    "        # linear transformation\n",
    "        out = torch.matmul(neighbors_agg.to(torch.float32), self.W2.to(torch.float32)) + torch.matmul(x.to(torch.float32), self.W1.to(torch.float32))\n",
    "        # relu activation\n",
    "        out = torch.relu(out)\n",
    "        return out\n",
    "\n",
    "'''Test the GNN Module'''\n",
    "# # input features from node attributes\n",
    "# x = torch.tensor([[G.nodes[i]['capacitance'],\n",
    "#                     G.nodes[i]['num_input_nodes'],\n",
    "#                     G.nodes[i]['input_cap'],\n",
    "#                     G.nodes[i]['output_cap'],\n",
    "#                     G.nodes[i]['connected_resistance'],\n",
    "#                     G.nodes[i]['input_resistance'],\n",
    "#                     G.nodes[i]['output_resistance'],\n",
    "#                     G.nodes[i]['elmore_cap'],\n",
    "#                     G.nodes[i]['elmore_delay']] for i in range(num_nodes)], dtype=torch.float)\n",
    "\n",
    "# print(\"Input Features: \", x)\n",
    "\n",
    "# # extract edge index from adjacency matrix from networkx\n",
    "# edge_index = torch.tensor([[i, j] for i in range(num_nodes) for j in range(num_nodes) if M_adj.A[i,j] != 0], dtype=torch.long).t()\n",
    "\n",
    "# # extract edge weights from networkx\n",
    "# edge_weight = torch.tensor([G.edges[i,j]['weight'] for i in range(num_nodes) for j in range(num_nodes) if M_adj.A[i,j] != 0], dtype=torch.float)\n",
    "\n",
    "# gnn = L1_GNNModule(num_node_features, num_node_features)\n",
    "# out = gnn(x, edge_index, edge_weight)\n",
    "\n",
    "# print(\"Output: \", out)\n",
    "# print(\"Output Shape: \", out.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\tilde{a}_{iu}^{(k, l_2)} = softmax(\\frac{W_Q^{(k, l_2)}x_i^{(L_1+l_2-1)}(W_k^{(k,l_2)}x_u^{(L_1+l_2-1)})}{\\sqrt{d_k}})$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$x_i^{(L_1+l_2)} = x_i^{(L_1+l_2-1)} +  W_3^{(l_2)}||^{\\mathcal{K}}_{k=1}\\sum_{u\\in \\mathcal{V}}\\tilde{a}_{iu}^{(k, l_2)}(W_V^{(k, l_2)}x_u^{(L_1+l_2-1)})$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Test the GNN Module'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class L2_GNNModule(nn.Module):\n",
    "    \"\"\"Multi-head Attention GNN module\n",
    "    \"\"\"\n",
    "    def __init__(self, num_input_features, num_output_features, num_of_heads=2):\n",
    "        super().__init__()\n",
    "        self.Wq = nn.Parameter(torch.randn(num_of_heads, num_input_features, num_output_features) * 0.01).to(torch.float32).to(mps_device)\n",
    "        self.Wk = nn.Parameter(torch.randn(num_of_heads, num_input_features, num_output_features) * 0.01).to(torch.float32).to(mps_device)\n",
    "        self.Wv = nn.Parameter(torch.randn(num_of_heads, num_input_features, num_output_features) * 0.01).to(torch.float32).to(mps_device)\n",
    "        self.W3 = nn.Parameter(torch.randn(num_input_features, num_output_features) * 0.01).to(torch.float32).to(mps_device)\n",
    "        self.num_of_heads = num_of_heads\n",
    "        self.num_output_features = num_output_features\n",
    "        \n",
    "\n",
    "    def forward(self, x, edge_index=None, edge_weight=None):\n",
    "        # self-attention map A\n",
    "        x = x.to(torch.float32)\n",
    "        \n",
    "        q = torch.matmul(x, self.Wq)\n",
    "        q = q.view(-1, self.num_of_heads, self.num_output_features)\n",
    "        k = torch.matmul(x, self.Wk)\n",
    "        k = k.view(-1, self.num_of_heads, self.num_output_features)\n",
    "        v = torch.matmul(x, self.Wv)\n",
    "        v = v.view(-1, self.num_of_heads, self.num_output_features)\n",
    "\n",
    "        # transpose to num_of_heads * num_nodes * num_node_features\n",
    "        q = q.transpose(0,1)\n",
    "        k = k.transpose(0,1)\n",
    "        v = v.transpose(0,1)\n",
    "\n",
    "        d_k = torch.tensor(self.num_output_features, dtype=torch.float)\n",
    "        a_iu = torch.matmul(q, k.transpose(-2, -1)) / torch.sqrt(d_k)\n",
    "        a_iu = torch.softmax(a_iu, dim=-1)\n",
    "        a_iu = torch.matmul(a_iu, v)\n",
    "\n",
    "        # concat heads\n",
    "        concat = a_iu.contiguous().view(self.num_of_heads, -1, self.num_output_features)\n",
    "        \n",
    "        # reshape to num_nodes * num_node_features by averaging over heads\n",
    "        concat = concat.transpose(0,1)\n",
    "        concat = concat.mean(dim=1)\n",
    "        # use max instead of mean\n",
    "        # concat = concat.max(dim=1)[0]\n",
    "\n",
    "        l3 = torch.matmul(concat, self.W3)\n",
    "        \n",
    "        x = x + l3\n",
    "\n",
    "        return x\n",
    "        \n",
    "\n",
    "'''Test the GNN Module'''\n",
    "# # input features from node attributes\n",
    "# x = torch.tensor([[G.nodes[i]['capacitance'],\n",
    "#                     G.nodes[i]['num_input_nodes'],\n",
    "#                     G.nodes[i]['input_cap'],\n",
    "#                     G.nodes[i]['output_cap'],\n",
    "#                     G.nodes[i]['connected_resistance'],\n",
    "#                     G.nodes[i]['input_resistance'],\n",
    "#                     G.nodes[i]['output_resistance'],\n",
    "#                     G.nodes[i]['elmore_cap'],\n",
    "#                     G.nodes[i]['elmore_delay']] for i in range(num_nodes)], dtype=torch.float)\n",
    "\n",
    "# gnn = L2_GNNModule(num_node_features, num_node_features)\n",
    "# out = gnn(x)\n",
    "\n",
    "# print(\"Output: \", out)\n",
    "# print(\"Output Shape: \", out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNtrans(nn.Module):\n",
    "    def __init__(self, num_node, num_node_features, num_path_features) -> None:\n",
    "        super().__init__()\n",
    "        self.num_node = num_node\n",
    "        self.num_node_features = num_node_features\n",
    "        self.num_path_features = num_path_features\n",
    "        self.gnn1 = L1_GNNModule(num_node, num_node_features)\n",
    "        self.gnn2 = L1_GNNModule(num_node, num_node_features)\n",
    "        self.gnn3 = L1_GNNModule(num_node, num_node_features)\n",
    "        self.gnn4 = L1_GNNModule(num_node, num_node_features)\n",
    "        self.gnn5 = L1_GNNModule(num_node, num_node_features)\n",
    "        self.gnn6 = L1_GNNModule(num_node, num_node_features)\n",
    "        self.gnn7 = L1_GNNModule(num_node, num_node_features)\n",
    "        self.gnn8 = L1_GNNModule(num_node, num_node_features)\n",
    "        self.gnn9 = L1_GNNModule(num_node, num_node_features)\n",
    "        self.gnn10 = L1_GNNModule(num_node, num_node_features)\n",
    "        self.trans1 = L2_GNNModule(num_node, num_node_features)\n",
    "        self.trans2 = L2_GNNModule(num_node, num_node_features)\n",
    "        self.trans3 = L2_GNNModule(num_node, num_node_features)\n",
    "        self.trans4 = L2_GNNModule(num_node, num_node_features)\n",
    "        self.trans5 = L2_GNNModule(num_node, num_node_features)\n",
    "        # MLP layer predicting slew and delay\n",
    "        self.linear_slew = nn.Linear(num_node_features + num_path_features, 1)\n",
    "        self.linear_delay = nn.Linear(num_node_features + num_path_features + 1, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight, path_indices, path_features):\n",
    "        x = self.gnn1(x, edge_index, edge_weight)\n",
    "        x = self.gnn2(x, edge_index, edge_weight)\n",
    "        x = self.gnn3(x, edge_index, edge_weight)\n",
    "        x = self.gnn4(x, edge_index, edge_weight)\n",
    "        x = self.gnn5(x, edge_index, edge_weight)\n",
    "        x = self.gnn6(x, edge_index, edge_weight)\n",
    "        x = self.gnn7(x, edge_index, edge_weight)\n",
    "        x = self.gnn8(x, edge_index, edge_weight)\n",
    "        x = self.gnn9(x, edge_index, edge_weight)\n",
    "        x = self.gnn10(x, edge_index, edge_weight)\n",
    "\n",
    "        x = self.trans1(x, edge_index, edge_weight)\n",
    "        x = self.trans2(x, edge_index, edge_weight)\n",
    "        x = self.trans3(x, edge_index, edge_weight)\n",
    "        x = self.trans4(x, edge_index, edge_weight)\n",
    "        x = self.trans5(x, edge_index, edge_weight)\n",
    "\n",
    "        # path aggregation\n",
    "        y = torch.zeros(len(path_indices), self.num_path_features + self.num_node_features)\n",
    "        # print(\"y: \", y.shape)\n",
    "\n",
    "        for path_index, path_feature in zip(path_indices, path_features):\n",
    "            # print(\"path_index: \", path_index)\n",
    "            # select node based on path index\n",
    "            x_path = torch.index_select(x, 0, path_index)\n",
    "            # average pooling based on each path\n",
    "            x_path = torch.mean(x_path, dim=0)\n",
    "            # concatenate with path features\n",
    "            x_path = torch.cat((x_path, path_feature))\n",
    "            # add a dimension\n",
    "            x_path = x_path.unsqueeze(0)\n",
    "            # print(\"x_path: \", x_path.shape)\n",
    "            \n",
    "            # append to output\n",
    "            torch.cat((y, x_path), dim=0)\n",
    "\n",
    "        # predict slew\n",
    "        slew = self.linear_slew(y)\n",
    "        # concatenate slew with path features\n",
    "        y = torch.cat((y, slew), dim=1)\n",
    "        # predict delay\n",
    "        delay = self.linear_delay(y)\n",
    "\n",
    "        return slew, delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''Test the GNN'''\n",
    "# # input features from node attributes\n",
    "# x = torch.tensor([[G.nodes[i]['capacitance'],\n",
    "#                     G.nodes[i]['num_input_nodes'],\n",
    "#                     G.nodes[i]['input_cap'],\n",
    "#                     G.nodes[i]['output_cap'],\n",
    "#                     G.nodes[i]['connected_resistance'],\n",
    "#                     G.nodes[i]['input_resistance'],\n",
    "#                     G.nodes[i]['output_resistance'],\n",
    "#                     G.nodes[i]['elmore_cap'],\n",
    "#                     G.nodes[i]['elmore_delay']] for i in range(num_nodes)], dtype=torch.float)\n",
    "\n",
    "# # extract edge index from adjacency matrix from networkx\n",
    "# edge_index = torch.tensor([[i, j] for i in range(num_nodes) for j in range(num_nodes) if M_adj.A[i,j] != 0], dtype=torch.long).t()\n",
    "\n",
    "# print(edge_index)\n",
    "\n",
    "# # extract edge weights from networkx\n",
    "# edge_weight = torch.tensor([G.edges[i,j]['weight'] for i in range(num_nodes) for j in range(num_nodes) if M_adj.A[i,j] != 0], dtype=torch.float)\n",
    "\n",
    "# # extract path indices from networkx : node along the path\n",
    "# all_path_indices = torch.tensor(list_of_paths, dtype=torch.long)\n",
    "\n",
    "# # extract path features from networkx\n",
    "# path_features = M_path\n",
    "                                \n",
    "# num_path_features = path_features.shape[1]\n",
    "\n",
    "# gnn = GNNtrans(num_node_features, num_node_features, num_path_features)\n",
    "# slew, delay = gnn(x, edge_index, edge_weight, all_path_indices, path_features)\n",
    "\n",
    "# slew_target = 0.1\n",
    "# slew_target = torch.tensor(slew_target, dtype=torch.float)\n",
    "# delay_target = 0.2\n",
    "# delay_target = torch.tensor(delay_target, dtype=torch.float)\n",
    "\n",
    "# print(\"Slew: \", slew)\n",
    "# print(\"Slew Shape: \", slew.shape)\n",
    "\n",
    "# print(\"Delay: \", delay)\n",
    "# print(\"Delay Shape: \", delay.shape)\n",
    "\n",
    "# print(\"x Shape: \", x.shape)\n",
    "# print(\"edge_index Shape: \", edge_index.shape)\n",
    "# print(\"edge_weight Shape: \", edge_weight.shape)\n",
    "# print(\"path_indices Shape: \", all_path_indices.shape)\n",
    "# print(\"path_features Shape: \", path_features.shape)\n",
    "# print(\"slew_target Shape: \", slew_target.shape)\n",
    "# print(\"delay_target Shape: \", delay_target.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pesudo-Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.Adam(gnn.parameters(), lr=0.01)\n",
    "\n",
    "# for epoch in range(10):\n",
    "#     optimizer.zero_grad()\n",
    "#     slew, delay = gnn(x, edge_index, edge_weight, all_path_indices, path_features)\n",
    "#     print(\"Slew: \", slew)\n",
    "#     print(\"Delay: \", delay)\n",
    "#     loss = F.mse_loss(slew, slew_target) + F.mse_loss(delay, delay_target)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "#     print(\"Epoch: \", epoch, \" Loss: \", loss.item())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_delay Shape:  torch.Size([10000])\n",
      "label_slew Shape:  torch.Size([10000])\n",
      "node_feature Shape:  torch.Size([10000, 9, 9])\n",
      "path_feature Shape:  torch.Size([10000, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import os\n",
    "\n",
    "# extract sample from path\n",
    "SAMPLE_DIR = \"./sample/\"\n",
    "\n",
    "# extract sample from path\n",
    "label_delay = np.load(os.path.join(SAMPLE_DIR, \"NumPath10000_NumStage8_label_delay.npy\"))\n",
    "label_delay = torch.from_numpy(label_delay)\n",
    "label_delay = label_delay.to(torch.float32).to(mps_device)\n",
    "label_slew = np.load(os.path.join(SAMPLE_DIR, \"NumPath10000_NumStage8_label_slew.npy\"))\n",
    "label_slew = torch.from_numpy(label_slew)\n",
    "label_slew = label_slew.to(torch.float32).to(mps_device)\n",
    "all_node_feature = np.load(os.path.join(SAMPLE_DIR, \"NumPath10000_NumStage8_node_features.npy\"))\n",
    "all_node_feature = torch.from_numpy(all_node_feature).to(torch.float32).to(mps_device)\n",
    "all_path_feature = np.load(os.path.join(SAMPLE_DIR, \"NumPath10000_NumStage8_path_features.npy\"))\n",
    "all_path_feature = np.expand_dims(all_path_feature, axis=1)\n",
    "all_path_feature = torch.from_numpy(all_path_feature).to(torch.float32).to(mps_device)\n",
    "\n",
    "print(\"label_delay Shape: \", label_delay.shape)\n",
    "print(\"label_slew Shape: \", label_slew.shape)\n",
    "print(\"node_feature Shape: \", all_node_feature.shape)\n",
    "print(\"path_feature Shape: \", all_path_feature.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.,  0.,  1.,  0., 46.,  1.,  0., 47.,  0.])\n",
      "tensor([ 7.,  1.,  2.,  7., 39.,  2.,  9., 38.,  1.])\n",
      "tensor([ 8.,  1.,  2., 15., 31.,  2., 18., 29.,  2.])\n",
      "num_node:  9\n",
      "num_path:  1\n",
      "num_node_features:  9\n",
      "num_path_features:  2\n",
      "torch.Size([2, 16])\n",
      "torch.Size([16])\n",
      "torch.Size([10000, 2, 16])\n",
      "torch.Size([10000, 16])\n"
     ]
    }
   ],
   "source": [
    "print(all_node_feature[0][0])\n",
    "print(all_node_feature[0][1])\n",
    "print(all_node_feature[0][2])\n",
    "\n",
    "num_samples = label_delay.shape[0]\n",
    "num_node = all_node_feature.shape[1]\n",
    "num_path = 1\n",
    "num_node_features = all_node_feature.shape[2]\n",
    "num_path_features = all_path_feature.shape[2]\n",
    "\n",
    "# print\n",
    "print(\"num_node: \", num_node)\n",
    "print(\"num_path: \", num_path)\n",
    "print(\"num_node_features: \", num_node_features)\n",
    "print(\"num_path_features: \", num_path_features)\n",
    "\n",
    "# build a adjacency matrix that all the nodes are connected to the previous and next node\n",
    "M_adj = np.zeros((num_node, num_node))\n",
    "for i in range(num_node):\n",
    "    if i == 0:\n",
    "        M_adj[i][i + 1] = all_node_feature[0][i][7]\n",
    "    elif i == num_node - 1:\n",
    "        M_adj[i][i - 1] = all_node_feature[0][i][6]\n",
    "    else:\n",
    "        M_adj[i][i - 1] = all_node_feature[0][i][6]\n",
    "        M_adj[i][i + 1] = all_node_feature[0][i][7]\n",
    "\n",
    "# print(M_adj)\n",
    "\n",
    "# from adjacency matrix to edge index and edge weight\n",
    "edge_index = torch.tensor(\n",
    "    [[i, j] for i in range(num_node) for j in range(num_node) if M_adj[i, j] != 0],\n",
    "    dtype=torch.long,\n",
    ").t()\n",
    "edge_weight = torch.tensor(\n",
    "    [M_adj[i, j] for i in range(num_node) for j in range(num_node) if M_adj[i, j] != 0],\n",
    "    dtype=torch.float,\n",
    ")\n",
    "\n",
    "print(edge_index.shape)\n",
    "print(edge_weight.shape)\n",
    "\n",
    "all_edge_index = []\n",
    "all_edge_weight = []\n",
    "# exit(0)\n",
    "\n",
    "# now iterate through all the samples and stack them together\n",
    "# edge_idx should be a 3D tensor of (10000, 2, 16)\n",
    "# edge_weight should be a 2D tensor of (10000, 16)\n",
    "\n",
    "for i in range(num_samples):\n",
    "    M_adj = np.zeros((num_node, num_node))\n",
    "    for j in range(num_node):\n",
    "        if j == 0:\n",
    "            M_adj[j][j + 1] = all_node_feature[i][j][7]\n",
    "        elif j == num_node - 1:\n",
    "            M_adj[j][j - 1] = all_node_feature[i][j][6]\n",
    "        else:\n",
    "            M_adj[j][j - 1] = all_node_feature[i][j][6]\n",
    "            M_adj[j][j + 1] = all_node_feature[i][j][7]\n",
    "    edge_index = torch.tensor(\n",
    "        [[j, k] for j in range(num_node) for k in range(num_node) if M_adj[j, k] != 0],\n",
    "        dtype=torch.long,\n",
    "    ).t()\n",
    "    edge_weight = torch.tensor(\n",
    "        [\n",
    "            M_adj[j, k]\n",
    "            for j in range(num_node)\n",
    "            for k in range(num_node)\n",
    "            if M_adj[j, k] != 0\n",
    "        ],\n",
    "        dtype=torch.float,\n",
    "    )\n",
    "    all_edge_index.append(edge_index)\n",
    "    all_edge_weight.append(edge_weight)\n",
    "\n",
    "all_edge_index = torch.stack(all_edge_index).to(mps_device)\n",
    "all_edge_weight = torch.stack(all_edge_weight).to(mps_device)\n",
    "\n",
    "print(all_edge_index.shape)\n",
    "print(all_edge_weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1, 9)\n"
     ]
    }
   ],
   "source": [
    "# path_indices should be a 3D tensor of (10000, 1, 9) containing the indices of the nodes in the path\n",
    "all_path_indices = np.zeros((num_samples, num_path, num_node))\n",
    "for i in range(num_samples):\n",
    "    all_path_indices[i][0] = np.arange(num_node)\n",
    "\n",
    "print(all_path_indices.shape)\n",
    "# to torch tensor with type int32\n",
    "all_path_indices = torch.from_numpy(all_path_indices)\n",
    "all_path_indices = all_path_indices.type(torch.int32).to(mps_device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zy/r66k3sqd0rjgb7f3t3s92tqr0000gn/T/ipykernel_27689/2949141321.py:32: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(slew, slew_target) + F.mse_loss(delay, delay_target)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0  Avg Loss:  2267725.7723976565\n",
      "Epoch:  1  Avg Loss:  809118.8778425743\n",
      "Epoch:  2  Avg Loss:  349312.38388794253\n",
      "Epoch:  3  Avg Loss:  304834.09741097386\n",
      "Epoch:  4  Avg Loss:  302798.37735558284\n",
      "Epoch:  5  Avg Loss:  302678.4872031021\n",
      "Epoch:  6  Avg Loss:  302665.00002223055\n",
      "Epoch:  7  Avg Loss:  302662.8593013771\n",
      "Epoch:  8  Avg Loss:  302662.49430473556\n",
      "Epoch:  9  Avg Loss:  302662.4198092445\n",
      "Epoch:  10  Avg Loss:  302662.4072329163\n",
      "Epoch:  11  Avg Loss:  302662.40449014056\n",
      "Epoch:  12  Avg Loss:  302662.4021612236\n",
      "Epoch:  13  Avg Loss:  302662.4008322304\n",
      "Epoch:  14  Avg Loss:  302662.4011094978\n",
      "Epoch:  15  Avg Loss:  302662.4024016266\n",
      "Epoch:  16  Avg Loss:  302662.4048609749\n",
      "Epoch:  17  Avg Loss:  302662.4076758743\n",
      "Epoch:  18  Avg Loss:  302662.4088848282\n",
      "Epoch:  19  Avg Loss:  302662.41024756164\n",
      "Epoch:  20  Avg Loss:  302662.4111315979\n",
      "Epoch:  21  Avg Loss:  302662.4110080864\n",
      "Epoch:  22  Avg Loss:  302662.4082800613\n",
      "Epoch:  23  Avg Loss:  302662.4098981918\n",
      "Epoch:  24  Avg Loss:  302662.41374585725\n",
      "Epoch:  25  Avg Loss:  302662.4144282211\n",
      "Epoch:  26  Avg Loss:  302662.4122691574\n",
      "Epoch:  27  Avg Loss:  302662.41369525145\n",
      "Epoch:  28  Avg Loss:  302662.4128865295\n",
      "Epoch:  29  Avg Loss:  302662.4124840111\n",
      "Epoch:  30  Avg Loss:  302662.41309692\n",
      "Epoch:  31  Avg Loss:  302662.4088262886\n",
      "Epoch:  32  Avg Loss:  302662.4090642914\n",
      "Epoch:  33  Avg Loss:  302662.4104268898\n",
      "Epoch:  34  Avg Loss:  302662.4085081375\n",
      "Epoch:  35  Avg Loss:  302662.4075961006\n",
      "Epoch:  36  Avg Loss:  302662.40809232485\n",
      "Epoch:  37  Avg Loss:  302662.40871404874\n",
      "Epoch:  38  Avg Loss:  302662.4070745453\n",
      "Epoch:  39  Avg Loss:  302662.40611282503\n",
      "Epoch:  40  Avg Loss:  302662.4081856354\n",
      "Epoch:  41  Avg Loss:  302662.40690520476\n",
      "Epoch:  42  Avg Loss:  302662.40671727445\n",
      "Epoch:  43  Avg Loss:  302662.40614069975\n",
      "Epoch:  44  Avg Loss:  302662.4066290413\n",
      "Epoch:  45  Avg Loss:  302662.406331337\n",
      "Epoch:  46  Avg Loss:  302662.40497928084\n",
      "Epoch:  47  Avg Loss:  302662.40560460207\n",
      "Epoch:  48  Avg Loss:  302662.4029656586\n",
      "Epoch:  49  Avg Loss:  302662.40213911975\n",
      "Epoch:  50  Avg Loss:  302662.40138351667\n",
      "Epoch:  51  Avg Loss:  302662.40234273375\n",
      "Epoch:  52  Avg Loss:  302662.4033945808\n",
      "Epoch:  53  Avg Loss:  302662.403311615\n",
      "Epoch:  54  Avg Loss:  302662.40464244154\n",
      "Epoch:  55  Avg Loss:  302662.40457106475\n",
      "Epoch:  56  Avg Loss:  302662.402964328\n",
      "Epoch:  57  Avg Loss:  302662.4052490555\n",
      "Epoch:  58  Avg Loss:  302662.4028902031\n",
      "Epoch:  59  Avg Loss:  302662.4064519455\n",
      "Epoch:  60  Avg Loss:  302662.4099654648\n",
      "Epoch:  61  Avg Loss:  302662.4071402542\n",
      "Epoch:  62  Avg Loss:  302662.4063805008\n",
      "Epoch:  63  Avg Loss:  302662.40505800326\n",
      "Epoch:  64  Avg Loss:  302662.40192580567\n",
      "Epoch:  65  Avg Loss:  302662.404167894\n",
      "Epoch:  66  Avg Loss:  302662.4029085388\n",
      "Epoch:  67  Avg Loss:  302662.4029661316\n",
      "Epoch:  68  Avg Loss:  302662.40161880647\n",
      "Epoch:  69  Avg Loss:  302662.4024985077\n",
      "Epoch:  70  Avg Loss:  302662.40212961275\n",
      "Epoch:  71  Avg Loss:  302662.4034683937\n",
      "Epoch:  72  Avg Loss:  302662.40202209016\n",
      "Epoch:  73  Avg Loss:  302662.4066339737\n",
      "Epoch:  74  Avg Loss:  302662.4030816833\n",
      "Epoch:  75  Avg Loss:  302662.4058084518\n",
      "Epoch:  76  Avg Loss:  302662.40632011567\n",
      "Epoch:  77  Avg Loss:  302662.40280485764\n",
      "Epoch:  78  Avg Loss:  302662.40350884094\n",
      "Epoch:  79  Avg Loss:  302662.4023633743\n",
      "Epoch:  80  Avg Loss:  302662.4028526894\n",
      "Epoch:  81  Avg Loss:  302662.40338282776\n",
      "Epoch:  82  Avg Loss:  302662.4018991165\n",
      "Epoch:  83  Avg Loss:  302662.4001524384\n",
      "Epoch:  84  Avg Loss:  302662.40078687284\n",
      "Epoch:  85  Avg Loss:  302662.4031613037\n",
      "Epoch:  86  Avg Loss:  302662.4037247986\n",
      "Epoch:  87  Avg Loss:  302662.4033532074\n",
      "Epoch:  88  Avg Loss:  302662.4049706581\n",
      "Epoch:  89  Avg Loss:  302662.4039969765\n",
      "Epoch:  90  Avg Loss:  302662.40213863755\n",
      "Epoch:  91  Avg Loss:  302662.39981407166\n",
      "Epoch:  92  Avg Loss:  302662.4006927765\n",
      "Epoch:  93  Avg Loss:  302662.4012249435\n",
      "Epoch:  94  Avg Loss:  302662.40024641954\n",
      "Epoch:  95  Avg Loss:  302662.4008231514\n",
      "Epoch:  96  Avg Loss:  302662.40080290986\n",
      "Epoch:  97  Avg Loss:  302662.39840343245\n",
      "Epoch:  98  Avg Loss:  302662.3967414505\n",
      "Epoch:  99  Avg Loss:  302662.40022434085\n"
     ]
    }
   ],
   "source": [
    "GNN = GNNtrans(num_node, num_node_features, num_path_features)\n",
    "GNN.to(mps_device)\n",
    "optimizer = torch.optim.Adam(GNN.parameters(), lr=0.1)\n",
    "\n",
    "loss_history = []\n",
    "\n",
    "for epoch in range(100):\n",
    "    epoch_loss = 0\n",
    "    for sample_idx, (node_feature, edge_idx, edge_weight, path_idx, path_feature, slew_target, delay_target) in enumerate(\n",
    "        zip(\n",
    "            all_node_feature,\n",
    "            all_edge_index,\n",
    "            all_edge_weight,\n",
    "            all_path_indices,\n",
    "            all_path_feature,\n",
    "            label_slew,\n",
    "            label_delay,\n",
    "        )\n",
    "    ):\n",
    "        optimizer.zero_grad()\n",
    "        # print input shapes\n",
    "        # print(\"node_feature Shape: \", node_feature.shape)\n",
    "        # print(\"edge_idx Shape: \", edge_idx.shape)\n",
    "        # print(\"edge_weight Shape: \", edge_weight.shape)\n",
    "        # print(\"path_idx Shape: \", path_idx.shape)\n",
    "        # print(\"path_feature Shape: \", path_feature.shape)\n",
    "        # print(\"slew_target Shape: \", slew_target.shape)\n",
    "        # print(\"delay_target Shape: \", delay_target.shape)\n",
    "        slew, delay = GNN(node_feature, edge_idx, edge_weight, path_idx, path_feature)\n",
    "        # print(\"predicted slew: \", slew)\n",
    "        # print(\"predicted delay: \", delay)\n",
    "        loss = F.mse_loss(slew, slew_target) + F.mse_loss(delay, delay_target)\n",
    "        # print(\"predicted slew: {}, target slew: {}\".format(slew, slew_target))\n",
    "        # print(\"predicted delay: {}, target delay: {}\".format(delay, delay_target))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    loss_history.append(epoch_loss / num_samples)\n",
    "\n",
    "    print(\"Epoch: \", epoch, \" Avg Loss: \", epoch_loss / num_samples)\n",
    "\n",
    "# save the model\n",
    "torch.save(GNN.state_dict(), \"GNNtrans.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted slew:  tensor([[1646.6053]], grad_fn=<AddmmBackward0>)\n",
      "predicted delay:  tensor([[645.2449]], grad_fn=<AddmmBackward0>)\n",
      "target slew:  tensor(2293.3000)\n",
      "target delay:  tensor(949.7000)\n"
     ]
    }
   ],
   "source": [
    "# reload the model\n",
    "GNN = GNNtrans(num_node, num_node_features, num_path_features)\n",
    "GNN.load_state_dict(torch.load(\"GNNtrans.pt\"))\n",
    "\n",
    "# test the model\n",
    "test_idx = 0\n",
    "test_node_feature = all_node_feature[test_idx]\n",
    "test_edge_index = all_edge_index[test_idx]\n",
    "test_edge_weight = all_edge_weight[test_idx]\n",
    "test_path_idx = all_path_indices[test_idx]\n",
    "test_path_feature = all_path_feature[test_idx]\n",
    "test_slew_target = label_slew[test_idx]\n",
    "test_delay_target = label_delay[test_idx]\n",
    "\n",
    "test_slew, test_delay = GNN(\n",
    "    test_node_feature,\n",
    "    test_edge_index,\n",
    "    test_edge_weight,\n",
    "    test_path_idx,\n",
    "    test_path_feature,\n",
    ")\n",
    "\n",
    "print(\"predicted slew: \", test_slew)\n",
    "print(\"predicted delay: \", test_delay)\n",
    "print(\"target slew: \", test_slew_target)\n",
    "print(\"target delay: \", test_delay_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "# plot the loss history\n",
    "plt.plot(loss_history)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss History\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "- Base : https://colab.research.google.com/github/VisiumCH/AMLD-2021-Graphs/blob/master/notebooks/workshop_notebook.ipynb#scrollTo=7kPXvM8OxMJS\n",
    "- GraphSAGE : https://colab.research.google.com/drive/1udeUfWJzvMlLO7sGUDGsHo8cRPMicajl?usp=sharing#scrollTo=wTR4wQG31Vtk\n",
    "- GAT : https://colab.research.google.com/github/PytorchLightning/lightning-tutorials/blob/publication/.notebooks/course_UvA-DL/06-graph-neural-networks.ipynb#scrollTo=6c42fc29"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
